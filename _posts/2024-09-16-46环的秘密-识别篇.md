---
title: 46 环的秘密—识别篇
data: 2024-09-16 19:32:36 +0800
categories: [RoboMaster, 能量机关]
tags: [RoboMaster, 计算机视觉, 能量机关]
math: true
description: 能量机关识别算法详解
author: zmsbruce
---

![](/assets/img/2024-09-16-46环的秘密-识别篇/cover.png)

# 使用神经网络识别的缺点

当今，流行的对能量机关的识别方式大多使用神经网络，其步骤为从神经网络得到能量机关的特征点，再代入到 PnP 计算中得到旋转角度信息。但这种方法存在着下面的缺点：
- **精确度较低：**神经网络高度依赖于人工标注的数据集。人工标注很难做到像素级别的精确度，这会带来识别准确度的降低，当为了兼顾自瞄采用焦距为 8mm 的镜头时，这一点会体现得更加明显。
- **耗时较长：**使用神经网络进行识别的方式在 NUC 上的时间会有 20-30ms 之多，这会对拟合的效果产生不利的影响。我们拿一场内含时间和旋转角度的[比赛数据](/assets/files/2024-05-25-09-51-16.csv)举例，对间隔为 5ms 的原数据和间隔 30ms 的采样后数据，使用相同的策略进行拟合，并计算 0.3s （24m/s 弹速下，子弹发射到击打到能量机关的时间）后的预测结果和真实结果之间的误差（rad），得到的结果如下图所示（左为原数据，右为采样数据，x 轴代表拟合次数，每 300ms 拟合一次）。可以看出，帧率的降低使得拟合的平均误差由 0.035rad 变化到了 0.05rad，增加了 42.86%. 而最大误差从 0.089rad 变化到了 0.115rad，增加了 29.21%.

![](/assets/img/2024-09-16-46环的秘密-识别篇/fit_error.png)
_左：间隔为 5ms 的拟合效果；右：间隔为 30ms 的拟合效果_

> 为了对误差角度有一个更加直观的认识，下面通过计算将其和环数联系在一起:
{: .prompt-tip}

设误差角度为 $$\alpha$$ ，则其反映在环数 对应的直径 $$\phi$$ 为：

$$
\phi=4R\cdot\sin\frac{\alpha}{2}
$$

那么我们可以计算每一环直径 $$\phi$$ 对应的误差角度 $$\alpha$$ 为：

$$
\alpha=2\arcsin\frac{\phi}{4R}
$$

从[规则手册](https://terra-1-g.djicdn.com/b2a076471c6c4b72b574a977334d3e05/RM2024/RoboMaster%202024%20%E6%9C%BA%E7%94%B2%E5%A4%A7%E5%B8%88%E8%B6%85%E7%BA%A7%E5%AF%B9%E6%8A%97%E8%B5%9B%E6%AF%94%E8%B5%9B%E8%A7%84%E5%88%99%E6%89%8B%E5%86%8CV2.1%EF%BC%8820240722%EF%BC%89.pdf)可以得到能量机关旋转半径、每环对应直径等信息，从而计算出误差角度、圆靶误差距离和误差环数的关系如下表：

| 环数  | 误差距离（mm） | 误差角度（rad） |
| :---: | :------------: | :-------------: |
|  10   |       15       |      0.021      |
|   9   |       30       |      0.043      |
|   8   |       45       |      0.064      |
|   7   |       60       |      0.086      |
|   6   |       75       |      0.107      |
|   5   |       90       |      0.129      |
|  ...  |      ...       |       ...       |

# 识别算法

接下来我们要介绍基于传统视觉算法的能量机关识别算法，其整体流程如下图所示：

![](/assets/img/2024-09-16-46环的秘密-识别篇/flow_light.png){: .light }
![](/assets/img/2024-09-16-46环的秘密-识别篇/flow_dark.png){: .dark }
_识别流程图_

## 预处理

算法的输入为曝光时间为 5ms 的工业相机的成像，以焦距为 12mm 的图像帧为例：

![](/assets/img/2024-09-16-46环的秘密-识别篇/input.png)
_输入图像_

> 不同焦距的成像可以通过修改参数解决，因此不影响识别算法的运行。但为了防止在装甲板切换时丢失视野，建议选择 FOV 覆盖整个能量机关的镜头。
{: .prompt-warning}

预处理步骤包括**通道提取**、根据全局 ROI 进行**图像裁切**、**通道相减**和**二值化**。进行图像裁切可以加快图像的处理速度，而进行通道相减可以有效滤除白色区域，减少后续的误识别，正如下图所示，为经过和未经过通道相减的使用相同阈值进行二值化处理的图像：

![](/assets/img/2024-09-16-46环的秘密-识别篇/channel_sub.png)
_左：经过通道相减；右：未经过通道相减_

此外，如果让二值化图像中装甲板的灯条和现实中的相近，就需要降低二值化阈值，但这会导致流水灯的灯条粘连，从而影响流水灯的识别与匹配，如下图所示。因此，为了防止识别出现问题，对于二值化处理，我们分别**为流水灯和装甲板设立了两套阈值参数**。

![](/assets/img/2024-09-16-46环的秘密-识别篇/threshold.png)
_左：适用于流水灯的阈值；右：适用于装甲板的阈值_

## 流水灯识别

流水灯的识别分为下面三个步骤：

- **寻找所有符合流水灯要求的灯条：**判据为灯条的依据为长宽比和外接矩形面积；
- **将这些灯条匹配成一个流水灯：**将灯条两两进行比对，如果二者的面积相似、且距离在一定范围内，则将其归为同一类。取包含灯条数目最多的一类作为流水灯所在的类；
- **对匹配到的流水灯进行判断：**分别对外接矩形面积和长宽比进行计算，如果符合要求，则成功识别到了流水灯；

尽管输入图像中可能会有很多与流水灯灯条相似的光源（如机器人的装甲板灯条、后方屏幕、天花板灯等），但由于会对灯条进行匹配，因此依旧能够成功地对流水灯进行识别。如下图所示，绿色为识别到的流水灯灯条，而白色为匹配得到的流水灯：

![](/assets/img/2024-09-16-46环的秘密-识别篇/arrow.png)
_流水灯识别结果可视化_

## 局部 ROI 的计算与子图获取

在成功识别完流水灯后，我们要进一步识别装甲板和中心 R，以得到特征点进行后续的 PnP 计算。但在进行进一步的识别之前，我们需要 ROI 将装甲板和旋转中心框出，再提取出子图来进行识别，这样可以**缩短识别需要的时间**，并**减少误识别**。

我们以流水灯中心为原点，以流水灯旋转矩形的长边为轴，以一个距离作两个方形框，作为局部 ROI，如下图所示：

![](/assets/img/2024-09-16-46环的秘密-识别篇/local_roi.png)
_局部 ROI_

之后我们得到装甲板和旋转中心的子图如下：

![](/assets/img/2024-09-16-46环的秘密-识别篇/sub_images.png)
_装甲板和旋转中心子图_

## 装甲板识别

在得到了两张子图之后，我们便开始进行装甲板的识别。然而，由于能量机关的几何性质，仅凭流水灯旋转矩形的角度，我们并不知道哪张图像对应着装甲板，哪张对应旋转中心。因此我们初步的想法为，假定一张图像为装甲板，对其进行识别。如果识别失败了，则对另一张进行识别。

上述的方法虽然合理，但会导致一半的概率需要识别两次图像，这会导致识别时间变长。此外，如果在旋转中心对应的图像里误识别了装甲板，那么就会得到完全错误的信息，这种情况在激活了多块装甲板的情况下会出现，如下图黄色部分所示：

![](/assets/img/2024-09-16-46环的秘密-识别篇/armor_misrecognized.png)
_在旋转中心子图中误识别装甲板_

为了减少先识别旋转中心子图的情况出现，我们可以将**上一帧识别装甲板和旋转中心的位置**作为先验，并对当前帧的两张子图分别计算距离，认定距离近的为装甲板子图。实验证明，除了装甲板切换会导致距离信息失效之外，其余情况下这种方法装甲板子图的认定是比较稳定的。

在其余方面，装甲板的识别步骤与流水灯的识别相差不大，也是**灯条识别——匹配——整体识别**。然而对于灯条识别而言，装甲板灯条需要判断**轮廓面积**，而非流水灯灯条的外接矩形面积。这是因为在某些情况下，由于流水灯箭头的流动，与流水灯相近的装甲板灯条在二值化图像上会与流水灯的箭头相连（如下图所示）。这种情况下，其外接矩形面积会变得非常大，不好作为判据。而轮廓面积并不会因此增加太多，因此可以作为面积的判据。

![](/assets/img/2024-09-16-46环的秘密-识别篇/armor_with_arrow_pinned.png)
_有流水灯灯条粘连的装甲板_

> 流水灯灯条的面积判据不采用轮廓面积的原因为：给定一个轮廓所有的点，求解轮廓面积需要消耗一定时间，而包括误识别的流水灯灯条数目数目可能会非常多，有时达到十几个，如果均对其求轮廓面积，会带来非常大的时间消耗。而装甲板灯条在其子图中不会出现太多，因此对其使用轮廓面积是很合适的。
{: .prompt-info}

对于装甲板灯条匹配，除了面积比和距离之外，还需要判断角度，以减少上图中的误识别情况出现。此外，对于相同的一类装甲板灯条，我们还可以判断其组成的装甲板中心和流水灯中心的距离，如果过近，那么也会认为是出现了上面的误识别。

## 旋转中心识别

在成功识别装甲板之后，我们对另一张图进行旋转中心的识别。识别旋转中心的风险比较高，因为很有可能将旋转中心附近的流水灯灯条、以及激活成功的灯板误认为旋转中心（如下图所示），这会造成 PnP 结果上巨大的误差。

![](/assets/img/2024-09-16-46环的秘密-识别篇/center.png)
_旋转中心二值化图_

因此，我们需要设立严格的判据，以确保正确识别：

- **旋转中心到外侧装甲板灯条的距离：**这可以滤除部分流水灯灯板和成功激活的灯板；
- **旋转中心到流水灯所在直线的距离：**这可以滤除部分成功激活的灯板；
- **外接矩形面积：**旋转中心的外接矩形面积通常大于流水灯灯板的面积；

## 全局 ROI 计算

在识别出装甲板和旋转中心之后，我们根据装甲板和旋转中心的距离，以旋转中心为中心，构造一个正方形框，如下图所示：

![](/assets/img/2024-09-16-46环的秘密-识别篇/global_roi.png)
_全局 ROI_

得到的全局 ROI 会用来对下一帧输入图像进行裁剪，从而减少计算时间。

## 特征点提取

在识别出装甲板和旋转中心之后，我们需要对其进行特征点提取，从而带入到 PnP 计算中进行旋转角度的获取。为了得到准确且稳定的结果，我们选择了装甲上灯板的三个顶点、装甲下灯板的两个顶点、以及旋转中心作为特征点。装甲板的特征点可以通过灯板的旋转矩形顶点计算得到，而旋转中心的特征点为其外接矩形的中点，如下图绿色点所示：

![](/assets/img/2024-09-16-46环的秘密-识别篇/feature_points.png)

> 不选择装甲下灯板的下方顶点的原因之前提到过，由于流水灯箭头的流动，与流水灯相近的装甲板灯条在二值化图像上会与流水灯的箭头相连，外接旋转矩形底边的中点有时不会是灯板下方顶点。
{: .prompt-info}

在得到特征点之后，我们便可以拿到其像素坐标，并根据其对应的物理坐标进行 PnP 计算，得出其旋转矩阵和平移向量，进而得到它的旋转角度，进行拟合和预测操作了~

# 相关代码

哈尔滨工业大学 2023 年能量机关识别代码：[https://github.com/zmsbruce/rm_power_rune](https://github.com/zmsbruce/rm_power_rune)
